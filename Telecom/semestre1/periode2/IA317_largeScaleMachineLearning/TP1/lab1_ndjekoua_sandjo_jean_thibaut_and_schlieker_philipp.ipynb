{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "lab1_ndjekoua sandjo_jean thibaut_and_schlieker_philipp.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaXt5wwAq51z",
        "colab_type": "text"
      },
      "source": [
        "# LAB: Random Projections : SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC5iap60q510",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### Authors: R. M. Gower\n",
        "\n",
        "## Aim\n",
        "\n",
        "The aim of this material is to\n",
        "- to show that in practice dimension reduction can be used with no loss of accuracy on some problem\n",
        "- code efficient sparse random projections\n",
        "- apply sparse random projections together with knearestneighbors\n",
        "\n",
        "\n",
        "## VERY IMPORTANT\n",
        "\n",
        "- This work **must be done by pairs of students**.\n",
        "- Each paris of students must send their jupyter notebook **before the 24th of November at 21:59** to **gowerrobert@gmail.com**\n",
        "- The **name of the file must be** constructed as in the next cell\n",
        "\n",
        "# Gentle reminder: no evaluation if you don't respect this EXACTLY\n",
        "\n",
        "### How to construct the name of your file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfmH5l19q511",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "914058f8-0108-4b19-c427-4640a5c57369"
      },
      "source": [
        "# Change here using YOUR first and last names\n",
        "fn1 = \"ndjekoua sandjo\"\n",
        "ln1 = \"jean thibaut\"\n",
        "fn2 = \"philipp\"\n",
        "ln2 = \"schlieker\"\n",
        "\n",
        "filename = \"_\".join(map(lambda s: s.strip().lower(), \n",
        "                        [\"lab1\", ln1, fn1, \"and\", ln2, fn2])) + \".ipynb\"\n",
        "print(filename)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lab1_jean thibaut_ndjekoua sandjo_and_schlieker_philipp.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00q87__4q515",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Throughout the notebook you will find commented boxes like this one\n",
        "\n",
        "### TODO ###   \n",
        "# please implement blabla\n",
        "#############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzHjvdNdq518",
        "colab_type": "text"
      },
      "source": [
        "These boxes need to be replaced by code as explained in the boxes.\n",
        "Solutions will online tomorrow. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0ydyiC3q519",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX32GQhCq52A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import norm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT8aqwV1q52C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression    #Logistic Regression\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "\n",
        "def get_data(dataname):\n",
        "    data = load_svmlight_file(dataname)\n",
        "    return data[0], data[1]\n",
        "\n",
        "\n",
        "# Supress warnings\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwTzbqYzq52E",
        "colab_type": "text"
      },
      "source": [
        "## EXERCISE 1: \n",
        "\n",
        "Use LogisticRegression classifier of Scikit-learn to experimentally confirm the following corollary proven in class and test random sparse projections\n",
        "\n",
        "### Corollary of Range Space Preserving Theorem  \n",
        "\n",
        "Let \n",
        "$$ X^\\top = [x_1, \\ldots, x_n]\\in \\mathbb{R}^{n\\times d},$$\n",
        "be our data matrix and let\n",
        "$$  X X^\\top= [\\hat{x}_1, \\ldots, \\hat{x}_n]^\\top \\in \\mathbb{R}^{d\\times d}. $$\n",
        "We can find a solution to the following training problem\n",
        "$$ w^* \\in \\min_{w \\in \\mathbb{R}^d}  \\frac{1}{n}\\sum_{i=1}^n \\ell_i(\\langle x_i,w \\rangle) \\hspace{3cm} (I)$$\n",
        "by instead solving \n",
        "$$ \\hat{w}^* \\in \\min_{w \\in \\mathbb{R}^n}  \\frac{1}{n}\\sum_{i=1}^n \\ell_i(\\langle \\hat{x}_i,w \\rangle) \\hspace{3cm} (II)$$\n",
        "and  $ X ^\\top \\hat{w}^*$ is a solution to $(I)$\n",
        "\n",
        "**NOTE:** The matrix $X$ is transposed with respect to the data matrix defined in class and in the lectures ! Be careful with dimnensions!\n",
        "### End Corollary\n",
        "\n",
        "1) [2pts] Show that by setting the regularization parameter close to zero (C = 10^9) in LogisticRegression, the score obtained by training using $X$ and $XX^\\top$ is the same\n",
        "  \n",
        "2) [2pts] Compute a solution $w^*_1$  by directly solving (I).  Compare this $w^*_1$ to the recovered solution $X \\hat{w}^*$. Are they the same? Justify based on Corollary.\n",
        "\n",
        "3) [6pts] Using a random generated gaussian matrix $W \\in\\mathbb{R}^{d\\times r}$ , project the data matrix $X \\rightarrow XW$. Test for different values of r and\n",
        "apply logistic regression to the resulting projected matrix. Can you explain what you observe? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24L4z7srq52F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f5c5432-5092-4d27-91fe-9168377572c0"
      },
      "source": [
        "# download the colon-cancer data set from \n",
        "# https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/colon-cancer.bz2\n",
        "# Unpack and place in the same folder as this python notebook\n",
        "dataname = \"colon-cancer\"  \n",
        "X, y = get_data(dataname)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "n, d = X_train.shape\n",
        "print('{n} data points and {d} features'.format(n = n,d =d))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41 data points and 2000 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMMWoYkRq52H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "df3570ed-03bd-408a-c264-8c09c73c1a75"
      },
      "source": [
        "C0 = 10**9 # almost no regularization, since this is the inverse of the regularization parameter, i.e, C = 1/lambda\n",
        "log_reg = LogisticRegression(C = C0) # , multi_class = \"multinomial\"\n",
        "log_reg.fit(X_train, y_train)\n",
        "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
        "print('Accuracy on the test set: {:.3f}'.format(log_reg.score(X_test,y_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the training set: 1.000\n",
            "Accuracy on the test set: 0.619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vNysFKcq52J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "915858ff-dd34-4763-e548-885a00121f23"
      },
      "source": [
        "### TODO ###   \n",
        "# 2)  Compute a solution $w^*_1$  by directly solving (I).  \n",
        "# Compare this $w^*_1$ to the recovered solution $X^\\top \\hat{w}^*$.\n",
        "# Are they the same? Justify based on Corollary.\n",
        "\n",
        "# Compute Solution for $w^*_1$\n",
        "log_reg_w = LogisticRegression(C = C0)\n",
        "log_reg_w.fit(X_train, y_train)\n",
        "print('Accuracy for solving X on the training set: {:.3f}'.format(log_reg_w.score(X_train,y_train)))\n",
        "print('Accuracy for solving X on the test set: {:.3f}'.format(log_reg_w.score(X_test,y_test)))\n",
        "\n",
        "# Compute Solution for $X^\\top \\hat{w}^*$\n",
        "log_reg_ws = LogisticRegression(C = C0)\n",
        "log_reg_ws.fit(X_train*X_train.T, y_train)\n",
        "print('Accuracy for solving XXT on the training set: {:.3f}'.format(log_reg_ws.score(X_train*X_train.T,y_train)))\n",
        "print('Accuracy for solving XXT on the test set: {:.3f}'.format(log_reg_ws.score(X_test*X_train.T,y_test)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for solving X on the training set: 1.000\n",
            "Accuracy for solving X on the test set: 0.619\n",
            "Accuracy for solving XXT on the training set: 1.000\n",
            "Accuracy for solving XXT on the test set: 0.619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOH84z2Cq52M",
        "colab_type": "text"
      },
      "source": [
        "#ANSWER TO QUESTION 1: \n",
        "as we can see from the previous output, the the accuracy obtained applying the test set on the trained models using both the models trained with\n",
        "$XX^\\top $ and $ X$ are the same. So the corollary is verified.\n",
        "\n",
        "#ANSWER TO QUESTION 2:\n",
        " The solutions are not identical, but we don't expect them to be necessarily identical, since the only thing $ X ^\\top \\hat{w}^*$ is showing, is that it is A solution and not the solution! In order to show that, we can recover the original coefficients and see if they also solve X_test.\n",
        "By doing so, we can see that $ X ^\\top \\hat{w}^*$ is A solution to (I) as shown by the Corollary of Range Space Preserving Theorem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10SxT2zwq52M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "38f5165e-21a4-46c3-de85-59cba164e270"
      },
      "source": [
        "# Calculate the differences between the solution for $w^*_1$ and the recovered solution for $X^\\top \\hat{w}^*$\n",
        "dist = np.sum(log_reg_w.coef_ - log_reg_ws.coef_ * X_train )\n",
        "print('Difference between $w^*_1$ and the recovered solution for Xtop: {:.3f}'.format(dist))\n",
        "\n",
        "# Hence we could expect that xtop * X_train will be a solution to X_test\n",
        "log_reg_ws.coef_ = log_reg_ws.coef_ * X_train\n",
        "\n",
        "print('Accuracy for solving X with the recovered coefficient from X_top on the training set: {:.3f}'.format(log_reg_ws.score(X_train,y_train)))\n",
        "print('Accuracy for solving X with the recovered coefficient from X_top on the test set: {:.3f}'.format(log_reg_ws.score(X_test,y_test)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Difference between $w^*_1$ and the recovered solution for Xtop: 1.941\n",
            "Accuracy for solving X with the recovered coefficient from X_top on the training set: 1.000\n",
            "Accuracy for solving X with the recovered coefficient from X_top on the test set: 0.619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4zyZE_yq52O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "f0c48250-ae71-4990-8a1d-5cfa0ec12bc2"
      },
      "source": [
        "### TODO ### \n",
        "## Choose a range of different projected dimensions to test\n",
        "## Suggested range of projected dimensions:\n",
        "upperbnd = d\n",
        "project_dimensions = range(1,upperbnd,int((upperbnd )/10))\n",
        "#############\n",
        "test_accuracy = []\n",
        "training_accuracy = []\n",
        "s = 20\n",
        "for r in project_dimensions: \n",
        "    ### TODO ###        \n",
        "    # 3)    project the data matrix $X \\rightarrow XW$ using Gaussian and fit, \n",
        "    #      transform and score using Logstic Regression\n",
        "    \n",
        "    W = np.random.normal(size=(d,r))\n",
        "    \n",
        "    # Fit Logistic Regression\n",
        "    log_reg = LogisticRegression(C = C0)\n",
        "    log_reg.fit(X_train * W, y_train)\n",
        "\n",
        "    # Recover Coefficients\n",
        "    log_reg.coef_ = log_reg.coef_.dot(W.T)\n",
        "\n",
        "    trainscore=log_reg.score(X_train,y_train)\n",
        "    training_accuracy.append(trainscore)\n",
        "    testscore=log_reg.score(X_test,y_test)\n",
        "    test_accuracy.append(testscore)\n",
        "    #############\n",
        "    print (\"project dimension %4d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))\n",
        "# coef_recover= log_regt.coef_.dot(X_train.transpose())\n",
        "\n",
        "plt.plot(project_dimensions,training_accuracy, label='Accuracy of the training set')\n",
        "plt.plot(project_dimensions,test_accuracy, label='Accuracy of the test set')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Projected Dimension')\n",
        "plt.legend()\n",
        "index_max = np.argmax(test_accuracy)\n",
        "print(\"Best score was for r =%5d with: (train, test) =  (%.4f, %.4f)\"% (project_dimensions[index_max], training_accuracy[index_max],test_accuracy[index_max]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "project dimension    1 gives: (train, test) =  (0.6829, 0.5714)\n",
            "project dimension  201 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension  401 gives: (train, test) =  (1.0000, 0.7619)\n",
            "project dimension  601 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension  801 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension 1001 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension 1201 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension 1401 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension 1601 gives: (train, test) =  (1.0000, 0.6190)\n",
            "project dimension 1801 gives: (train, test) =  (1.0000, 0.6190)\n",
            "Best score was for r =  401 with: (train, test) =  (1.0000, 0.7619)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERhjTJSzRGCMMVHu/wE4+QPv3Cz6fwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jbH0lSFq52Q",
        "colab_type": "text"
      },
      "source": [
        "#ANSWER TO QUESTION 3 \n",
        "The accuracies obtained here are quite similiar to the ones we obtained in the previous exercise. The partially improved accuracy can be explained by taking into account that by reducing the dimensions the problem of overfitting is reduced. Also from a certain value on, the accuracy on the training set becomes constant while it starts decreasing on the test set. So in conclusion, it's better to choose small values for the projected dimession r."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vHjE7pTq52R",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2:\n",
        "\n",
        "In class we used \n",
        "$$ X \\rightarrow W^\\top X $$\n",
        "But here it is instead\n",
        "$$ X \\rightarrow X W $$\n",
        "\n",
        "\n",
        "\n",
        "Now we will train a model using a large text based data set. For this you need to code the following random transform $W \\in \\mathbb{R}^{d \\times r}$ that takes a sparsity parameter $s$ as an input and outputs a matrix\n",
        "\n",
        "$$ W_{ij}  = \\sqrt{\\frac{s}{r}}\n",
        "\\begin{cases}\n",
        "1 \\quad & \\mbox{with probability }\\frac{1}{2s} \\\\\n",
        "0 \\quad & \\mbox{with probability }1-\\frac{1}{s} \\\\\n",
        "-1 \\quad & \\mbox{with probability }\\frac{1}{2s} \n",
        "\\end{cases}$$\n",
        "\n",
        "* Code a function Generate_Sparse_Transform$(s,r,d)$ that takes an input  \n",
        "   * sparsity parameter  $s$\n",
        "   * input dimension $d \\in \\mathbb{N}$\n",
        "   * lower dimensional projected dimension $r \\in \\mathbb{N}$\n",
        "and gives as outputs the matrix $W$ stored in an efficient sparse format such as the CSC formart (see scipy.sparse.csc_matrix)\n",
        "\n",
        "* Code a function Apply_Sparse_Transform$(R,X)$ that takes an input\n",
        "   * the random transform $W$ as generated by  Generate\\_sparse\\_transform$(s,r,d)$\n",
        "   * a given data matrix $X \\in \\mathbb{R}^{n\\times d}$\n",
        "the output will be $XW$.\n",
        "\n",
        "\n",
        "*Note* if you have not implemented this efficiently, you will probably run out of memory!  \n",
        "\n",
        "\n",
        "We will test if random projections are able to preserve pairwise distances by applying K-Neighrest Neighbors to projected data.\n",
        "\n",
        "1) [6pts] Code the above two functions (their stub is provided below)\n",
        "\n",
        "\n",
        "2) [1pt] Load the data set X. Then fit, transform and score sklearn's KNeighborsClassifier on this data, where \n",
        "$X = $ {anthracyclineTaxaneChemotherapy, sector.scale}. Below you will find how to load this data.\n",
        "\n",
        "3) [3pts] Repeat the previous step, but first randomly project that data using X -> XW. Repeat this test for different values of the sparsity parameter s and projected dimension parameter r. What can you conclude? \n",
        "\n",
        "*Hint* As a rule of thumb $s = \\sqrt{r}$, $s= \\log(r)$ or simply $s=20$ often works well.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgVR28Dkq52R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from sklearn.utils.extmath import safe_sparse_dot   ## <-- I recommend using this function\n",
        "from sklearn.utils.random import sample_without_replacement  ## <-- I recommend using this function\n",
        "\n",
        "def GenerateSparseTransform(s,r,d):\n",
        "    ### TODO ### \n",
        "    ##  Implement this function. Make sure that W is a sparse matrix!\n",
        "    #############\n",
        "    val = np.sqrt(s/r)\n",
        "    \n",
        "    cnt = 0\n",
        "    \n",
        "    data = []\n",
        "    rowindex = []\n",
        "    colptr = []\n",
        "       \n",
        "    for i in range(r):\n",
        "        for j in range(d):\n",
        "            rand = np.random.random()\n",
        "                        \n",
        "            if rand < (1/(2 * s)):\n",
        "                v = val\n",
        "            elif rand < (1-(1/(2.0 * s))):\n",
        "                v = 0\n",
        "            else:\n",
        "                v = -val\n",
        "            \n",
        "            if v != 0:\n",
        "                data.append(v)\n",
        "                rowindex.append(j)\n",
        "                colptr.append(i)\n",
        "\n",
        "    W=scipy.sparse.csc_matrix((data, (rowindex, colptr)), shape=(d, r))\n",
        "    return W\n",
        "\n",
        "def ApplySparseTransform(W,X_):\n",
        "#     W   : Sparse randomly generated matrix of size d by r\n",
        "#     X_  : Data matrix to be compressed, of size n by d\n",
        "#    NOTE: The dimensions of W and X_ are such that the product X_*W is defined (which is different that what we used in class)\n",
        "    ### TODO ### \n",
        "    ##  Implement this function. Make sure that W is a sparse matrix!\n",
        "    #############\n",
        "    \n",
        "    #d = (X_.shape[0], W[0][1])    \n",
        "    #Xtransformed = np.zeros(shape = d)\n",
        "\n",
        "    #for i in range(d[0]):\n",
        "    #    ptr = 0\n",
        "    #    for j in range(d[1]):\n",
        "    #        for p in range(ptr, ptr + W[3][j]):\n",
        "    #            Xtransformed[i,j] += X_[i,W[2][ptr]] * W[1][ptr]\n",
        "    \n",
        "    # Since a library function was given in the beginning, let's use that one since it will be better in any case, then the own implementation\n",
        "    \n",
        "    Xtransformed = safe_sparse_dot(X_, W)\n",
        "    return Xtransformed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct4ouSohq52T",
        "colab_type": "text"
      },
      "source": [
        "## Load and test easier data set *anthracyclineTaxaneChemotherapy*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWyAeMeuq52U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "chemo = fetch_openml(name='anthracyclineTaxaneChemotherapy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJMn8G8q52V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = chemo.data\n",
        "y = chemo.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UyhgMT6q52X",
        "colab_type": "text"
      },
      "source": [
        "### if fetch_openml fails  \n",
        "**ALTERNATIVE HACK for loading the data**\n",
        "  \n",
        "* downloard the data from data set in arff format from: https://www.openml.org/d/1085\n",
        " \n",
        "* place data in the same folder as this notebook and run the code in the next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0DCrimyq52Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3ae7ff51-8f8e-432d-ad0b-861bbca356ae"
      },
      "source": [
        "## ALTERNATIVE HACK for loading anthracyclineTaxaneChemotherapy ## \n",
        "\"\"\"from scipy.io import arff\n",
        "dataset = arff.loadarff('phpCLGrjq.arff')\n",
        "import pandas as pd\n",
        "Xdf = pd.DataFrame(dataset[0])\n",
        "Xy = Xdf.as_matrix()\n",
        "n_rows, n_cols = Xy.shape\n",
        "X = Xy[:,:-1]\n",
        "X = np.float_(X)\n",
        "y = Xy[:,-1]\n",
        "y = (np.int_(y))*2-3\"\"\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from scipy.io import arff\\ndataset = arff.loadarff('phpCLGrjq.arff')\\nimport pandas as pd\\nXdf = pd.DataFrame(dataset[0])\\nXy = Xdf.as_matrix()\\nn_rows, n_cols = Xy.shape\\nX = Xy[:,:-1]\\nX = np.float_(X)\\ny = Xy[:,-1]\\ny = (np.int_(y))*2-3\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFLpk569q52Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1fbcfbd-1a5f-4ea3-ce23-2da19661aa1e"
      },
      "source": [
        "# split test and training. Only use 20% of data for testing because data set is small. \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) \n",
        "n, d = X_train.shape\n",
        "print('{n} training data points and {d} features'.format(n = n,d =d))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127 training data points and 61359 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4fV301hq52c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84a6bc61-1e33-4bbc-bca7-e0072da82beb"
      },
      "source": [
        "# 2) fit, transform and score the knn Classifier\n",
        "n_neighbors =2 # <-- use this number of neighbours\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "knn.fit(X_train,y_train)\n",
        "trainscore = knn.score(X_train, y_train)\n",
        "training_accuracy.append(trainscore)\n",
        "testscore = knn.score(X_test, y_test)\n",
        "test_accuracy.append(knn.score(X_test, y_test))\n",
        "print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (d, trainscore,testscore))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "project dim 61359 gives: (train, test) =  (0.8425, 0.5625)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU7Amueoq52f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "outputId": "ec66e21f-def1-4333-80de-729bce6e75a9"
      },
      "source": [
        "test_accuracy = []\n",
        "training_accuracy = []\n",
        "n_neighbors =2  #< -- I recommend 2 neighbors\n",
        "\n",
        "## Suggested range of projected dimensions:\n",
        "upperbnd = int(min(10*n,d/2))\n",
        "minbnd = int(max(n/20,d/2000))\n",
        "project_dimensions = range(minbnd,upperbnd,int((upperbnd -minbnd)/10))\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    \n",
        "for r in project_dimensions:  \n",
        "    W = GenerateSparseTransform(s =20, r= r,d = d) # function coded above\n",
        "    Xt_train = ApplySparseTransform(W,X_train)  # function coded above\n",
        "    Xt_test =  ApplySparseTransform(W,X_test)  # function coded above\n",
        "    knn.fit(Xt_train,y_train)\n",
        "    trainscore = knn.score(Xt_train, y_train)\n",
        "    training_accuracy.append(trainscore)\n",
        "    testscore = knn.score(Xt_test, y_test)\n",
        "    test_accuracy.append(knn.score(Xt_test, y_test))\n",
        "    print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))\n",
        "\n",
        "list_proj_dims = list(project_dimensions)\n",
        "plt.plot(list_proj_dims,training_accuracy, label='Accuracy of the training set')\n",
        "plt.plot(list_proj_dims,test_accuracy, label='Accuracy of the test set')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Projected Dimension')\n",
        "plt.legend()\n",
        "index_max = np.argmax(test_accuracy)\n",
        "print(\"Best score was for r =%5d with: (train, test) =  (%.4f, %.4f)\"% (list_proj_dims[index_max], training_accuracy[index_max],test_accuracy[index_max]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "project dim    30 gives: (train, test) =  (0.8189, 0.6875)\n",
            "project dim   154 gives: (train, test) =  (0.8504, 0.5938)\n",
            "project dim   278 gives: (train, test) =  (0.8110, 0.5312)\n",
            "project dim   402 gives: (train, test) =  (0.7953, 0.5625)\n",
            "project dim   526 gives: (train, test) =  (0.8346, 0.5625)\n",
            "project dim   650 gives: (train, test) =  (0.8661, 0.6250)\n",
            "project dim   774 gives: (train, test) =  (0.8425, 0.5000)\n",
            "project dim   898 gives: (train, test) =  (0.8346, 0.5625)\n",
            "project dim  1022 gives: (train, test) =  (0.8110, 0.6250)\n",
            "project dim  1146 gives: (train, test) =  (0.8110, 0.6562)\n",
            "Best score was for r =   30 with: (train, test) =  (0.8189, 0.6875)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYd0dLwRq52h",
        "colab_type": "text"
      },
      "source": [
        "## Load and test HARDER data set *sector.scale*  \n",
        "**(only try this data set after successfully testing the anthracyclineTaxaneChemotherapy data set)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SNPKiTUq52i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06939b86-8ca6-473d-fa8d-e097e8907d5b"
      },
      "source": [
        "# Download the data set from:\n",
        "# https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/sector/sector.scale.bz2\n",
        "# place data in the same folder as this python notebook\n",
        "dataname = \"sector.scale\"  \n",
        "X, y = get_data(dataname)\n",
        "n, d = X.shape\n",
        "print('{n} data points and {d} features'.format(n = n,d =d))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6412 data points and 55197 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYPDPScKq52o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "457996e0-fe52-4a18-cc20-55dd67186375"
      },
      "source": [
        "# split test and training \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "n, d = X_train.shape\n",
        "print('{n} trainig data points and {d} features'.format(n = n,d =d))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4296 trainig data points and 55197 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi57gXIvq52t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### TODO ### \n",
        "## repeat the same experiments for this larger data set\n",
        "## HINT: Only test project dimensions r <= int(min(2*n,d/2))\n",
        "#############"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7bxHqmZq52v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "986568bf-d3ce-4845-bb0c-108e1a65812a"
      },
      "source": [
        "test_accuracy = []\n",
        "training_accuracy = []\n",
        "n_neighbors =1   ## <-- I recommend using this\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "upperbnd = int(min(2*n,d/2))\n",
        "minbnd = int(max(n/20,d/2000))\n",
        "project_dimensions = range(minbnd,upperbnd,int((upperbnd -minbnd)/10))\n",
        "    \n",
        "for r in project_dimensions:  \n",
        "    ### TODO ###   \n",
        "    # 3)    project the data matrix $X \\rightarrow XW$ using Gaussian and fit, \n",
        "    #      transform and score using knn  \n",
        "    W = GenerateSparseTransform(s=20, r= r,d = d) # function coded above\n",
        "    Xt_train = ApplySparseTransform(W,X_train)  # function coded above\n",
        "    Xt_test =  ApplySparseTransform(W,X_test)  # function coded above\n",
        "    knn.fit(Xt_train,y_train)\n",
        "    trainscore = knn.score(Xt_train, y_train)\n",
        "    training_accuracy.append(trainscore)\n",
        "    testscore = knn.score(Xt_test, y_test)\n",
        "    test_accuracy.append(knn.score(Xt_test, y_test))\n",
        "    #############\n",
        "    print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))\n",
        "\n",
        "list_proj_dims = list(project_dimensions)\n",
        "plt.plot(list_proj_dims,training_accuracy, label='Accuracy of the training set')\n",
        "plt.plot(list_proj_dims,test_accuracy, label='Accuracy of the test set')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Projected Dimension')\n",
        "plt.legend()\n",
        "index_max = np.argmax(test_accuracy)\n",
        "print(\"Best score was for r =%5d with: (train, test) =  (%.4f, %.4f)\"% (list_proj_dims[index_max], training_accuracy[index_max],test_accuracy[index_max]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "project dim   214 gives: (train, test) =  (1.0000, 0.7623)\n",
            "project dim  1051 gives: (train, test) =  (1.0000, 0.8629)\n",
            "project dim  1888 gives: (train, test) =  (1.0000, 0.8767)\n",
            "project dim  2725 gives: (train, test) =  (1.0000, 0.8762)\n",
            "project dim  3562 gives: (train, test) =  (1.0000, 0.8795)\n",
            "project dim  4399 gives: (train, test) =  (1.0000, 0.8781)\n",
            "project dim  5236 gives: (train, test) =  (1.0000, 0.8823)\n",
            "project dim  6073 gives: (train, test) =  (1.0000, 0.8781)\n",
            "project dim  6910 gives: (train, test) =  (1.0000, 0.8809)\n",
            "project dim  7747 gives: (train, test) =  (1.0000, 0.8828)\n",
            "project dim  8584 gives: (train, test) =  (1.0000, 0.8790)\n",
            "Best score was for r = 7747 with: (train, test) =  (1.0000, 0.8828)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCES1cFcq52x",
        "colab_type": "text"
      },
      "source": [
        "## Bonus question\n",
        "\n",
        "Using the Jonhson-Lindenstrauss Lemma, we can have an estimate for the projected dimension using\n",
        "\n",
        "$$r = \\frac{1}{\\epsilon^2}\\log(n/\\delta) $$\n",
        "\n",
        "1) Write a function for calculating this given suggested project dimension r. \n",
        "2) Test for each of the above data sets with \\epsilon = 0.05 = \\delta and compare to your results. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5oX_08iq52y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "delta = .05\n",
        "eps = 0.05\n",
        "def ComputeJL(n,delta,eps):\n",
        "    \n",
        "    return int((1 / epsilon**2)*np.log(n/delta))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHmAV8PqA-LC",
        "colab_type": "text"
      },
      "source": [
        "#TEST OF PRJECTED DIMESSION r WITH THE CHEMO DATA SET\n",
        "\n",
        "NB: the accuracy using a value of r obtained from the Jonhson-Lindenstrauss Lemma(0.65) is quite similar to the best accuracy obtained testing with different values of r.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYedwslbBBjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "749f5f74-ba04-42c2-f3bc-b406349941a7"
      },
      "source": [
        "X = chemo.data\n",
        "y = chemo.target\n",
        "# split test and training. Only use 20% of data for testing because data set is small. \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42) \n",
        "n, d = X_train.shape\n",
        "print('{n} training data points and {d} features'.format(n = n,d =d))\n",
        "r = ComputeJL(n = n,delta=delta,eps=eps)\n",
        "#train on the transformed data\n",
        "#W has shape d*r\n",
        "W = GenerateSparseTransform(s =20, r= r,d = d) # function coded above\n",
        "Xt_train = ApplySparseTransform(W,X_train)  # function coded above\n",
        "Xt_test =  ApplySparseTransform(W,X_test)  # function coded above\n",
        "knn.fit(Xt_train,y_train)\n",
        "trainscore = knn.score(Xt_train, y_train)\n",
        "training_accuracy.append(trainscore)\n",
        "testscore = knn.score(Xt_test, y_test)\n",
        "test_accuracy.append(knn.score(Xt_test, y_test))\n",
        "print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127 training data points and 61359 features\n",
            "project dim  3135 gives: (train, test) =  (1.0000, 0.6250)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGihpkhABDnI",
        "colab_type": "text"
      },
      "source": [
        "#TEST OF THE PROJECTED DIMESSION WITH THE HARDER DATA SET: sector.scale\n",
        "\n",
        "We shall also notice here how the accuracy obtained using the Jonhson-Lindenstrauss Lemma is quite similar to the best accuracy obtained trying with different values of r. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF6NRDCjBFzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2c96fdc8-4068-40da-f92c-44b941fc5954"
      },
      "source": [
        "X, y = get_data(dataname)\n",
        "n, d = X.shape\n",
        "\n",
        "# split test and training \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "n, d = X_train.shape\n",
        "print('{n} trainig data points and {d} features'.format(n = n,d =d))\n",
        "\n",
        "r = ComputeJL(n = n,delta=delta,eps=eps)\n",
        "#train on the transformed data\n",
        "#W has shape d*r\n",
        "W = GenerateSparseTransform(s =20, r= r,d = d) # function coded above\n",
        "Xt_train = ApplySparseTransform(W,X_train)  # function coded above\n",
        "Xt_test =  ApplySparseTransform(W,X_test)  # function coded above\n",
        "knn.fit(Xt_train,y_train)\n",
        "trainscore = knn.score(Xt_train, y_train)\n",
        "training_accuracy.append(trainscore)\n",
        "testscore = knn.score(Xt_test, y_test)\n",
        "test_accuracy.append(knn.score(Xt_test, y_test))\n",
        "print (\"project dim %5d gives: (train, test) =  (%.4f, %.4f)\" % (r, trainscore,testscore))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4296 trainig data points and 55197 features\n",
            "project dim  4544 gives: (train, test) =  (1.0000, 0.8781)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}